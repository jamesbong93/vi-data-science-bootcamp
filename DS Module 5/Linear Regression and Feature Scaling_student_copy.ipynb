{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grHqeO_q7bTD"
   },
   "source": [
    "<img src=\"./img/vi_logo.png\" style=\"float: left; margin: 10px; height: 45px\">\n",
    "\n",
    "# Vertical Institute Data Science 101\n",
    "# Lesson 5: Linear Regression and Feature Scaling\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "164WcogX7bTG"
   },
   "source": [
    "### Learning Objectives\n",
    "\n",
    "#### Part 1: Linear Regression\n",
    "**After this lesson, you will be able to:**\n",
    "- Define the terms: modeling, prediction\n",
    "- Understand the best line of a set of data\n",
    "- Find the best fit line by hand\n",
    "\n",
    "#### Part 2: Feature Scaling\n",
    "**After this lesson, you will be able to:**\n",
    "- Understand the importance of scaling data\n",
    "- Understand different ways to normalize data\n",
    "- Use Scikit-learn preprocessing to scale data in various ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQmSzGMJ7bTI"
   },
   "source": [
    "***Modeling and Predictions***\n",
    "\n",
    "Consider the following scenario:\n",
    "\n",
    "A manager at the bank is disturbed with more and more customers leaving their credit card services. They would really appreciate if one could predict for them who is gonna get churned so they can proactively go to the customer to provide them better services and turn customers' decisions in the opposite direction\n",
    "\n",
    "With models, we can make __predictions__\n",
    "\n",
    "- Models are relationships between quantities\n",
    "- Linear Regression is a method in determining the coefficients of linear relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Workflow\n",
    "\n",
    "- Training data during model training\n",
    "    - Labels provided\n",
    "- Testing data during prediction \n",
    "    - Labels not provided, to be predicted\n",
    "    \n",
    "    \n",
    "- Training and testing data go through the same preprocessing flow to reach the same shape before fed to model\n",
    "    - Outlier removal\n",
    "    - Standardizing\n",
    "    - Filling in missing values\n",
    "    - Data Transformations \n",
    "        - Encoding\n",
    "        - Pivoting\n",
    "        - GroupBy\n",
    "        - Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus on how columns are broken down into Training Data and Labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T14:08:12.606109Z",
     "start_time": "2021-10-29T14:08:12.602621Z"
    }
   },
   "source": [
    "<img src=\"img/flow.png\" style=\"height:400px\">\n",
    "Credits: https://www.researchgate.net/figure/A-flowchart-of-a-supervised-machine-learning-model_fig1_314202159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDewBTNP7bTK"
   },
   "source": [
    "## Linear Regression\n",
    "\n",
    "- Interactive explanation: https://setosa.io/ev/ordinary-least-squares-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB8Naeb67bTK"
   },
   "source": [
    "<img src=\"img/linreg.png\" style=\"margin: 20px; height: 400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-rL-h5w7bTL"
   },
   "source": [
    "***Linear regression*** is an analysis that assesses whether one or more predictor variables explain the dependent (criterion) variable.  \n",
    "The regression has five key assumptions:\n",
    "\n",
    "1. Linear relationship\n",
    "2. No or little multicollinearity\n",
    "3. No auto-correlation\n",
    "4. Homoscedasticity\n",
    "5. Residuals are Normally Distributed\n",
    "\n",
    "- less important if you only care about prediction (MSE) and not inference (coefficients of predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bZN2p6i7bTM"
   },
   "source": [
    "<img src=\"img/eqn.png\" style=\"margin: 20px; height: 30px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khW2y_qz7bTN"
   },
   "source": [
    "Check for a linear relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PlWAeGw7bTO"
   },
   "source": [
    "<img src=\"img/check_line.png\" style=\"margin: 20px; height: 300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5YMvzZW7bTP"
   },
   "source": [
    "Let's investigate the housing dataset with linear regression. We'll use two different packages and you can see examples for linear regression of each:\n",
    "- **statsmodels** (more for inference) -- http://statsmodels.sourceforge.net/devel/examples/#regression\n",
    "- **scikit-learn** (more for prediction) -- http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWlubfGY7bTQ"
   },
   "source": [
    "## Intro to Scikit-Learn\n",
    "\n",
    "Scikit-learn is a machine learning package for python that includes a huge array of models including linear regression. Scikit-learn includes a number of sample data sets including the Boston housing data set. (We could also load the data with pandas as in the last lesson.)\n",
    "\n",
    "<img src=\"img/ml_map.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T05:36:01.509757Z",
     "start_time": "2021-11-06T05:36:01.506990Z"
    },
    "id": "t1P0Xtiv7bTQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIdBEGtx7bTX"
   },
   "source": [
    "### Insurance dataset\n",
    "\n",
    "We will be studying how variables like age, gender and smoker can affect the insurance charges paid by customers. Subsequently, we will be building several models to predict the insurance charges using the same variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T05:58:47.134154Z",
     "start_time": "2021-11-06T05:58:47.127017Z"
    },
    "id": "iNE7uGj57bTX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('insurance.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T05:58:47.544380Z",
     "start_time": "2021-11-06T05:58:47.539438Z"
    },
    "id": "gP0E9C6e7bTZ",
    "outputId": "b484a08e-e073-4f64-bdb2-4e80fdb24528"
   },
   "outputs": [],
   "source": [
    "# Put the target in it's own series because sklearn needs predictors and targets as separate inputs to .fit()\n",
    "y = df['charges'] \n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCTSXcd57bTa"
   },
   "source": [
    "## Sklearn model fitting workflow\n",
    "- **Import** libraries and functions\n",
    "- **Instantiate** the model from its imported class\n",
    "- **Fit** this instance of the model using X (features) and y (labels)\n",
    "- **Predict** on X(usually different from X used to train) to get predicted y\n",
    "- **Evaluate** by comparing true y vs predicted y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below here is the skeleton structure for Linear Regression\n",
    "\n",
    "`\n",
    "from sklearn.linear_model import LinearRegression  # import \n",
    "from sklearn.metrics import mean_squared_error # import \n",
    "lm = LinearRegression()  # Instantiate a linear regression model\n",
    "lm.fit(X, y)    # Fit the model on predictors (2D object) and target (1D object)\n",
    "predictions = lm.predict(X_test) # Use fitted model to predict on the NEW unseen data\n",
    "mean_squared_error(y_test, predictions)   # compare true values with predictions using a performance metric\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVudvU2w7bTb"
   },
   "source": [
    "### `bmi` as feature \n",
    "\n",
    "- X variable usually used to mean the predictors \n",
    "    - They have to be all numbers, so object dtypes like categories or text must be transformed first\n",
    "    - This object has to be 2D because Sklearn is designed to fit on 2D objects\n",
    "    - Almost all Sklearn models cannot handle missing data, so make no None or np.NaN in X or y\n",
    "- y variable usually used to mean the target\n",
    "\n",
    "- You should name them with more meaningful names when it's not obvious what they are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T05:58:48.258989Z",
     "start_time": "2021-11-06T05:58:48.255507Z"
    },
    "id": "Ah2I4aRr7bTb"
   },
   "outputs": [],
   "source": [
    "# Select X\n",
    "X = df[[\"bmi\"]]   # Why not df['bmi']? Because sklearn needs 2D object for all X its models fits on\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T05:58:48.678470Z",
     "start_time": "2021-11-06T05:58:48.466121Z"
    },
    "id": "yTpLUXSo7bTc",
    "outputId": "a7096adc-e39e-4897-d204-9039e92b4f78"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Let's plot the relationship between X and y\n",
    "# We see a good visual indicator for a linear relationship\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel('bmi')\n",
    "plt.ylabel('Charges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the fitting process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T05:44:07.576698Z",
     "start_time": "2021-11-06T05:44:07.567884Z"
    },
    "id": "RUWnAuUX7bTd",
    "outputId": "3aac1c83-3727-4fa3-ade8-ef8e8903c74d"
   },
   "outputs": [],
   "source": [
    "#Let's try fitting the data into a linear model\n",
    "\n",
    "# Step 1 - Import the library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Step 2 - create an instance of model\n",
    "\n",
    "\n",
    "# Step 3 - fit the variables into the model\n",
    "# Notice that the fit method is ran in-place, the result need not be assigned to a new variable\n",
    "\n",
    "\n",
    "# Step 4 - use the model to predict your dependent variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the attributes from the fitted model + How to read documentation\n",
    "\n",
    "- Attributes ending with _ come about after fitting, they are not available before the model is fit on training data\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T03:49:32.918740Z",
     "start_time": "2021-11-04T03:49:32.913598Z"
    },
    "id": "FYquVR647bTe",
    "outputId": "2b8dcd1d-72ad-4c44-cc47-c9a973483cc6"
   },
   "outputs": [],
   "source": [
    "# what the predicted y-value is when all predictors are 0\n",
    "print(lm.intercept_)\n",
    "\n",
    "# how much y increases per unit increase in the corresponding predictor keeping all other predictors constant\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T01:59:22.862970Z",
     "start_time": "2021-11-06T01:59:22.658115Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot scatter plot here\n",
    "plt.scatter(X,y)\n",
    "plt.xlabel('bmi')\n",
    "plt.ylabel('Charges')\n",
    "\n",
    "# only need to prepare (x,y) coords of 2 endpoints to plot the predicted line\n",
    "x = np.array([X.min(),X.max()])\n",
    "y_pred = x * lm.coef_ + lm.intercept_\n",
    "\n",
    "plt.plot(x,y_pred,c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTvPa6Rq7bTh"
   },
   "source": [
    "### Evaluation of the model\n",
    "\n",
    "- Sklearn has many metrics provided for each type of modelling task (regression/classification), you don't have to code your own: https://scikit-learn.org/stable/modules/classes.html#regression-metrics\n",
    "- Most metrics are symmetric\n",
    "    - if you swap the 2 input parameters they give same result eg. A+B = B+A \n",
    "    - Good practice is to provide values to the metric functions in order of true, predicted\n",
    "    - `mean_squared_error(y_true,y_pred)` instead of `mean_squared_error(y_pred,y_true)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE first checks the difference between our prediction vs. the actual value of the target. (Actual - Prediction)\n",
    "\n",
    "Then it squares this error value to eliminate negative values.\n",
    "\n",
    "Finally, report the average of all MSEs.\n",
    "\n",
    "\n",
    " $$MSE = \\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}{(Actual_i -Predicted_i)^2}$$\n",
    "\n",
    "actual | prediction | error | squared_error\n",
    "---|---|---|---\n",
    "15|10|5|25\n",
    "10|12|-2|4\n",
    "\n",
    "```\n",
    "sum_squared_error = (15-10)**2 + (10-12)**2\n",
    "              = 5**2 + (-2)**2\n",
    "              = 25 + 4 \n",
    "              = 29\n",
    "mean_squared_error = squared_error/n\n",
    "                   = 29/2\n",
    "        \n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T05:51:14.390877Z",
     "start_time": "2021-11-06T05:51:14.387278Z"
    },
    "id": "QBDdU1Ub7bTj",
    "outputId": "af21c079-fa77-4051-82d5-6a2609a3d32e"
   },
   "outputs": [],
   "source": [
    "# Sklearn.metrics provides us a function to calculate MSE easily\n",
    "from _____.______ import ___________\n",
    "\n",
    "\n",
    "print(_______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Disadvantages of MSE\n",
    "- Sensitive to scale\n",
    "    - If y-values were * 100, MSE will be * 100, making it hard to compare model across different problems with different y\n",
    "    - If comparing across different y is not necessary (like when staying on 1 problem with 1 y), MSE works fine comparing among the same scale relatively\n",
    "- Penalizes errors non-linearly because of the square\n",
    "    - You may want to do Mean Absolute Error instead which doesn't square: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5W7ZjeT87bTl"
   },
   "source": [
    "### `Age` as feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:21:29.969265Z",
     "start_time": "2021-11-06T06:21:29.610978Z"
    },
    "id": "krnUnwOu7bTl",
    "outputId": "f0d1d539-6786-40a0-dd5a-b36fc8310386"
   },
   "outputs": [],
   "source": [
    "# Select X and y\n",
    "X = df[[\"age\"]]\n",
    "y = df['charges']\n",
    "\n",
    "# We have written a function to conveniently train the model, make predictions, plot the graphs, \n",
    "# compute the metrics in one shot! That's the power of a user defined function\n",
    "def train_predict(X,y):\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X, y)\n",
    "    predictions = lm.predict(X)\n",
    "\n",
    "    # Plot graph if only 1 independent variable\n",
    "    if X.shape[1] == 1:\n",
    "        plt.scatter(X,y)\n",
    "\n",
    "        # Plot our linear regression model    \n",
    "        x = np.array([X.min(), X.max()])\n",
    "        y_pred = x * lm.coef_ + lm.intercept_\n",
    "        plt.plot(x,y_pred,c='r')    \n",
    "    \n",
    "    # Compute the metrics\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "    \n",
    "    print(\"MSE:\", mse)   \n",
    "    print(\"Coefficients: \",lm.coef_)\n",
    "    print(\"Intercept: \",lm.intercept_)\n",
    "    \n",
    "    return lm.coef_,lm.intercept_\n",
    "\n",
    "train_predict(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn6DOAN07bTm"
   },
   "source": [
    "### Exercise \n",
    "\n",
    "- Let's try to use both **bmi** and **age** as predictors\n",
    "- Notice how model.coef_ has 2 coefficients in array now\n",
    "    - Compare the 2 coefficients with the coefficients when they were the sole predictors, what do you observe?\n",
    "- Hint: For practice of the sklearn model fitting workflow, try to do it without using the `train_predict` function first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T15:43:59.334197Z",
     "start_time": "2021-08-02T15:43:59.331630Z"
    },
    "id": "mD6ZkKwC7bTn"
   },
   "outputs": [],
   "source": [
    "# Fill in the blanks below\n",
    "\n",
    "# import the model \n",
    "from sklearn.linear_model import ___\n",
    "\n",
    "# prepare the data\n",
    "X = df[['bmi','age']]\n",
    "y = df['charges']\n",
    "\n",
    "# instantiate the model\n",
    "lm = ____\n",
    "\n",
    "# fit the model\n",
    "__________(X,y)\n",
    "\n",
    "# predict on the same X (usually we predict on new X, but that's for later)\n",
    "__ = lm.___(_)\n",
    "\n",
    "# evaluate your results using regression-based metrics\n",
    "mse = mean_squared_error(__,__)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#already defined function\n",
    "X = df[['bmi','age']]\n",
    "y = df['charges']\n",
    "\n",
    "train_predict(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rnux0MsB7bTp"
   },
   "source": [
    "### More detailed exploration (why 3 lines when age as predictor?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:22:25.188409Z",
     "start_time": "2021-11-06T06:22:25.171101Z"
    },
    "id": "6FfRrL937bTq",
    "outputId": "0d34d47b-95b0-48c9-a6da-75fa1f5c34da"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:22:25.867989Z",
     "start_time": "2021-11-06T06:22:25.863373Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T04:34:04.113674Z",
     "start_time": "2021-11-04T04:34:03.077580Z"
    },
    "id": "Xs76FpJs7bTq",
    "outputId": "a80b8f6c-abc6-4584-933b-ce8b9b4f8d4a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hue can be used to group to multiple data variable and show the dependency of the passed data values are to be plotted\n",
    "# Hue: variables that define the subsets of the data\n",
    "sns.scatterplot(x='age',y='charges',data=df, hue='sex')\n",
    "plt.show()\n",
    "sns.scatterplot(x='age',y='charges',data=df, hue='smoker')\n",
    "plt.show()\n",
    "sns.scatterplot(x='age',y='charges',data=df, hue='region')\n",
    "plt.show()\n",
    "\n",
    "# children is numeric dtype, but because of low cardinality (number of unique values), we can still hue sensibly\n",
    "sns.scatterplot(x='age',y='charges',data=df, hue='children') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretations from tests of various columns being hue\n",
    "- Smoker column looks most interesting\n",
    "- It seems that Smokers have consistently higher charges than non-smokers no matter the age\n",
    "- That are a mix of smokers and non-smokers in the 10000 to 30000 range, further investigation using more variables is required\n",
    "- It may be that the data required to separate them is not even in the dataset \n",
    "    - Form a hypothesis of what new metrics should be collected\n",
    "    - Consider cost of collection at scale, if scalable, try to collect the new metric for a small group of people\n",
    "    first to test effectiveness of new metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivqDKHXb7bTq"
   },
   "source": [
    "<a id='compare'></a>\n",
    "## Comparing the models\n",
    "\n",
    "A perfect fit would yield a straight line when we plot the predicted values versus the true values. We'll quantify the goodness of fit soon.\n",
    "\n",
    "### Build a model with just the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T02:44:09.108321Z",
     "start_time": "2021-11-06T02:44:09.106152Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df['charges'] # using charges as y\n",
    "X = df[['age', 'bmi', 'children']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:31:19.471681Z",
     "start_time": "2021-11-06T06:31:19.264745Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_predict(X,y)  # note how MSE reduced from 133million to 128 million with the addition of children variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:32:32.255702Z",
     "start_time": "2021-11-06T06:32:29.038727Z"
    }
   },
   "outputs": [],
   "source": [
    "# reload data again just in case\n",
    "df = pd.read_csv('insurance.csv')\n",
    "\n",
    "# See df.corr\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pairplot\n",
    "sns.pairplot(df,diag_kind='kde')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why `df.corr()` is not enough \n",
    "\n",
    "- Pearson's correlation unable to see non-linearities (curved relationships)\n",
    "- Unable to see groupwise regressions (there are 3 lines in age vs charges)\n",
    "- Unable to see that max charges decrease as children increase\n",
    "\n",
    "Pairplot interpretations\n",
    "\n",
    "- Age looks positively correlated with charges\n",
    "- Children looks negatively correlated with the max charge value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to add smoker (categorical data) as a feature? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:35:29.948695Z",
     "start_time": "2021-11-06T06:35:29.934915Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OrdinalEncoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:38:03.195184Z",
     "start_time": "2021-11-06T06:38:03.181820Z"
    }
   },
   "outputs": [],
   "source": [
    "# only run series.map() once! \n",
    "# Values in columns that are not found in keys of mapping dictionary will be converted to nan\n",
    "# restart from pd.read_csv if make this mistake\n",
    "df['smoker'] = df['smoker'].map({'yes':1,\n",
    "                                 'no':0}) \n",
    "\n",
    "df.head() # always check data after a transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to take a look at smoker vs age\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:38:04.880117Z",
     "start_time": "2021-11-06T06:38:04.655100Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [\"age\", \"smoker\"]\n",
    "X = df[features]\n",
    "y = df['charges']\n",
    "\n",
    "train_predict(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Massive drop in MSE from 133 million with age as only predictor to 40 million by adding smoker\n",
    "- R-squared jumped from 0.09 to 0.72\n",
    "- Actual vs predicted reduced from 3 lines to 2 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding \n",
    "- If using model for inference (using coefficient sizes to determine predictor importance), beware of dummy variable trap\n",
    "- https://towardsdatascience.com/beware-of-the-dummy-variable-trap-in-pandas-727e8e6b8bde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is pd.get_dummies?\n",
    "\n",
    "Let's run the following and take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:39:54.022630Z",
     "start_time": "2021-11-06T06:39:54.007753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data again just in case\n",
    "df = pd.read_csv('insurance.csv')\n",
    "# BEFORE using dummy\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFTER using dummy\n",
    "dummies_df = pd.________(df, columns=['______'])\n",
    "dummies_df.head(2)  # note pandas generated new column names for you by appending categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:43:43.246093Z",
     "start_time": "2021-11-06T06:43:43.008492Z"
    }
   },
   "outputs": [],
   "source": [
    "# for this problem you will get same MSE (although different coefficients) no matter which of 3 combinations\n",
    "# things will be different if one-hot-encoding columns with 3 or more categories\n",
    "# features = [\"age\",\"smoker_no\"]\n",
    "# features = [\"age\",\"smoker_yes\"]\n",
    "features = [\"age\",\"smoker_no\",\"smoker_yes\"]\n",
    "\n",
    "X = dummies_df[features]\n",
    "y = dummies_df['charges']\n",
    "\n",
    "train_predict(X,y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtD9N9R87bTx"
   },
   "source": [
    "## Part 2: Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjgDJLTw7bTy"
   },
   "source": [
    "***Why do we need to scale data?***\n",
    "- To handle disparities in units\n",
    "- Many distance-based machine learning models require scaling (K-nearest Neighbors, K-means, Regularized regressions)\n",
    "- Can speed up iterative model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrKnChG-7bTy"
   },
   "source": [
    "***How do we scale our data?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0EJmWuR7bTy"
   },
   "source": [
    "### Feature Scaling: Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:54:25.546531Z",
     "start_time": "2021-11-06T06:54:25.542251Z"
    },
    "id": "o0fhW8i07bTz"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import linear_model and mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:54:27.574123Z",
     "start_time": "2021-11-06T06:54:27.547338Z"
    },
    "id": "OE6mN3jz7bTz",
    "outputId": "fa612571-32d4-49a0-bd01-c70dfb8434da"
   },
   "outputs": [],
   "source": [
    "# Load the Boston Housing dataset\n",
    "df = pd.read_csv(\"boston_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2j4p6zLl7bT0"
   },
   "source": [
    "### Scaling our data\n",
    "\n",
    "Let's see what effect scaling our data has on some of the features by picking two features\n",
    "that have a large difference in scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T03:17:07.085658Z",
     "start_time": "2021-11-06T03:17:06.915779Z"
    },
    "id": "YdCgV5aK7bT0",
    "outputId": "94567782-62b9-4cd0-83a3-8876c9c11c13"
   },
   "outputs": [],
   "source": [
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "\n",
    "# plot a scatter plot\n",
    "plt.____(xs, ys)\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the min and max of TAX?\n",
    "- What are the min and max of NOX?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTnHg0Fi7bT1"
   },
   "source": [
    "<a id='standardization'></a>\n",
    "## Standardization\n",
    "- Also called Z-score normalization\n",
    "- Rescales to have a mean of zero and a variance of 1\n",
    "\n",
    "<img src=\"img/standardization.png\" style=\"margin: 20px; height: 200px\">\n",
    "\n",
    "Let's apply standardization, transforming our data to have mean zero $(\\mu = 0)$ and variance 1 $(\\sigma^2 = 1)$ by the formula:\n",
    "\n",
    "$$ x' = \\frac{x - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Sklearn StandardScaler\n",
    "\n",
    "- StandardScaler is one of the many transformers: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fit-transform workflow\n",
    "\n",
    "1. initialize transformer  `ss = StandardScaler()`\n",
    "2. fit transformer     `ss.fit(data)`\n",
    "3. apply transformer on same/new data. `ss.transform(data)`\n",
    "\n",
    "___\n",
    "If fitting and transforming on same data, `fit_transform()` is a faster version of `fit()` then `transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-06T06:57:54.705334Z",
     "start_time": "2021-11-06T06:57:54.522902Z"
    },
    "id": "xO1OIjU17bT2",
    "outputId": "cadca07e-975e-4efa-b2b8-2609a9b5beb2"
   },
   "outputs": [],
   "source": [
    "# import package\n",
    "from sklearn.________ import __________\n",
    "\n",
    "\n",
    "# initialize transformer \n",
    "ss = ____________()\n",
    "\n",
    "# fit the scaler object\n",
    "ss.fit(df[['NOX','TAX']])\n",
    "\n",
    "# transform the original variables\n",
    "df[['NOX','TAX']] = ss.transform(df[['NOX','TAX']]) # remember to assign back to update\n",
    "\n",
    "# You can also do this in one shot\n",
    "# df[['NOX','TAX']] = ss.fit_transform(df[['NOX','TAX']]) # fit and transform at the same time\n",
    "\n",
    "# plot the scatter plot\n",
    "plt.scatter(df['NOX'], df['TAX'], color='r')\n",
    "plt.xlabel(\"NOX standardized\")\n",
    "plt.ylabel(\"TAX standardized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is happening under the hood when we do ss.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.mean_, ss.scale_  # these show what standard scaler learned from fitting on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYVpcUPU7bT3"
   },
   "source": [
    "<a id='minmax'></a>\n",
    "### Min-Max Scaling (Another kind of scaling! There are many more variety)\n",
    "- Simple rescaling of data to fit a defined interval\n",
    "- We use the formula:\n",
    "\n",
    "$$x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InhNkCnU7bT7"
   },
   "source": [
    "## Lesson Summary\n",
    "\n",
    "\n",
    "Let's review what we learned today. We:\n",
    "\n",
    "- Applied linear regression to the insurance dataset\n",
    "- Used different tools such as statsmodels and scikit-learn to perform statistical algorithms\n",
    "- Understood the importance of feature scaling for certain predictive models\n",
    "- Used standardization and min-max scaling to the boston dataset and observed effects on regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0ZUBZg67bT7"
   },
   "source": [
    "# Readings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T05:12:00.635042Z",
     "start_time": "2021-10-10T05:12:00.629146Z"
    },
    "id": "3RqTZFav7bT7"
   },
   "source": [
    "Linear Regression Assumptions:\n",
    "- Assumptions of linear regression: https://towardsdatascience.com/linear-regression-assumptions-why-is-it-important-af28438a44a1 \n",
    "\n",
    "Sklearn:\n",
    "\n",
    "- Common pitfalls interpreting coefficients: https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html\n",
    "- Comparing Supervised learning algorithms: https://www.dataschool.io/comparing-supervised-learning-algorithms/\n",
    "- Sklearn preprocessing guide: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Free Sklearn Course with 50 short videos: https://courses.dataschool.io/scikit-learn-tips\n",
    "\n",
    "Statistics:\n",
    "- Easy channel to get first exposure to any stats concept: https://www.youtube.com/watch?v=PaFPbb66DxQ&list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU&ab_channel=StatQuestwithJoshStarmer\n",
    "- Understanding metrics with Venn Diagrams: https://www.andrewheiss.com/blog/2021/08/21/r2-euler/\n",
    "- 2 sets of notations for sum of squares: https://365datascience.com/tutorials/statistics-tutorials/sum-squares/\n",
    "\n",
    "ML Crash Course:\n",
    "- https://developers.google.com/machine-learning/crash-course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Channel for a start on any stats concept: https://www.youtube.com/watch?v=PaFPbb66DxQ&list=PLblh5JKOoLUIzaEkCLIUxQFjPIlapw8nU&ab_channel=StatQuestwithJoshStarmer"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TIdBEGtx7bTX",
    "OVudvU2w7bTb",
    "UTvPa6Rq7bTh",
    "5W7ZjeT87bTl",
    "qn6DOAN07bTm",
    "Rnux0MsB7bTp",
    "N2BeKHES7bTu",
    "FR-st2-x7bTx",
    "m0EJmWuR7bTy",
    "2j4p6zLl7bT0",
    "fYVpcUPU7bT3",
    "yAFaRBlO7bT5"
   ],
   "name": "Linear Regression and Feature Scaling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "426.667px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T13:23:41.506222Z",
     "start_time": "2021-10-09T13:23:41.500717Z"
    }
   },
   "source": [
    "<img src=\"./img/vi_logo.png\" style=\"float: left; margin: 10px; height: 45px\">\n",
    "\n",
    "# Vertical Institute Data Science 101\n",
    "# Lesson 4: Data Cleaning, Visualization and EDA\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Learning Objectives\n",
    "\n",
    "#### Part 1: Data Visualization\n",
    "**After this lesson, you will be able to:**\n",
    "- Understanding which visualization to use\n",
    "- Use the following visualization for data analysis\n",
    "    1. Line plots\n",
    "    2. Bar graphs\n",
    "    3. Scatter plots\n",
    "    4. Histograms\n",
    "- Change parameters of graphs such as style, color and size\n",
    "- Use seaborn package\n",
    "\n",
    "#### Part 2: Data Cleaning & EDA\n",
    "**After this lesson, you will be able to:**\n",
    "- Do basic data cleaning\n",
    "- Create functions and apply to dataframes\n",
    "- Use group by method and aggregate functions to fill data\n",
    "- Handle missing values\n",
    "- Perform basic exploratory data analysis using data manipulation tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/bank_graphs.png\" style=\"margin: 20px; height: 550px\">\n",
    "\n",
    "Source: https://www.slingshotapp.io/blog/9-best-data-visualization-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of Matplotlib\n",
    "\n",
    "- Python library specializing in the development of two-dimensional charts (including 3d charts)- \n",
    "- Data visualization is an important part of data analytics\n",
    "- Key features:\n",
    "    1. Good control over graphics elements\n",
    "    2. Exportable in many formats such as PNG, SVG, and EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:14:13.808447Z",
     "start_time": "2021-10-31T05:14:13.805545Z"
    }
   },
   "outputs": [],
   "source": [
    "#import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:14:39.293049Z",
     "start_time": "2021-10-31T05:14:39.289203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import data. Generating some random data\n",
    "np.random.seed(42) # this ensures that all of us get the same random numbers\n",
    "company_sales_df = pd.DataFrame(np.random.randint(low = 300, high = 5000, size = (10, 4)), \n",
    "                   columns=['company_1', 'company_2', 'company_3', 'company_4'],\n",
    "                   index=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'July', 'Aug', 'Sep', 'Oct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:14:40.602069Z",
     "start_time": "2021-10-31T05:14:40.592185Z"
    }
   },
   "outputs": [],
   "source": [
    "company_sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:14:48.043196Z",
     "start_time": "2021-10-31T05:14:47.856953Z"
    }
   },
   "outputs": [],
   "source": [
    "company_sales_df.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "- Plot company_1 and company_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T07:45:23.160786Z",
     "start_time": "2021-10-26T07:45:23.157475Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "cols_to_show = [__________]\n",
    "company_sales_df[________].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Size\n",
    " - figsize(width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T01:30:53.213499Z",
     "start_time": "2021-10-31T01:30:52.924416Z"
    }
   },
   "outputs": [],
   "source": [
    "company_sales_df.plot(_____________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Style Markers and Color\n",
    "\n",
    "- Shorthand syntax for color, marker, linestyle: https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.axes.Axes.plot.html#matplotlib.axes.Axes.plot\n",
    "- Changing markers to represent different types of data: https://matplotlib.org/3.2.1/api/markers_api.html#module-matplotlib.markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:19:33.187837Z",
     "start_time": "2021-10-31T05:19:32.945507Z"
    }
   },
   "outputs": [],
   "source": [
    "company_sales_df[['company_1']].plot(\\\n",
    "                                  style={'company_1': '--rd'},\n",
    "                                  markersize=10\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"others\"></a>\n",
    "***Titles, legends and labels***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:21:59.971819Z",
     "start_time": "2021-10-31T05:21:59.684400Z"
    }
   },
   "outputs": [],
   "source": [
    "#changing the label orientation\n",
    "# possible legend locations: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html\n",
    "company_sales_df.plot(figsize = (16, 8), \n",
    "                        fontsize = 20, \n",
    "                        rot = -50, \n",
    "                        title = 'Big Rotated Labels - Tiny Title')\n",
    "\n",
    "plt.legend(loc='upper left', fontsize=20) # type the wrong words in loc to see the possible values in error message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Providing some properties later \n",
    "- Create a partially styled plot first\n",
    "- Get references to what visual elements you want to edit\n",
    "- Edit them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:22:31.645787Z",
     "start_time": "2021-10-31T05:22:31.356426Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = company_sales_df.plot(figsize=(16,8), fontsize=20)\n",
    "\n",
    "# you can delay adding properties to a figure after it has been created \n",
    "\n",
    "plt.title('Sales against Sale Month', fontsize=21, y=1.01)\n",
    "\n",
    "plt.xlabel('Sale Month',fontsize=20)   # the stateless way\n",
    "\n",
    "plt.ylabel('Sales',fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "**1.b Write the code to show the plot below:**  \n",
    "Using the company_sales_df dataframe:  \n",
    "1. Set the figure size to 16 by 8.\n",
    "2. Give it a title of `Company Sales against Month` with a fontsize of 22.\n",
    "3. Set a y label  of `Company Sales` and an x label equal to `Months`.\n",
    "4. Give both labels a fontsize of 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T09:21:56.004242Z",
     "start_time": "2021-08-03T09:21:56.000586Z"
    }
   },
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bar\"></a>\n",
    "## Bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T01:49:26.310398Z",
     "start_time": "2021-10-31T01:49:26.298834Z"
    }
   },
   "outputs": [],
   "source": [
    "company_sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:30:42.453526Z",
     "start_time": "2021-10-31T05:30:42.184183Z"
    }
   },
   "outputs": [],
   "source": [
    "company_sales_df.plot(__________________) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T07:48:00.963071Z",
     "start_time": "2021-10-26T07:48:00.691064Z"
    }
   },
   "outputs": [],
   "source": [
    "#horizontal bars\n",
    "# list of all possible values in kind: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
    "company_sales_df.plot(kind='barh', figsize=(8,16)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked bars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T01:52:14.450402Z",
     "start_time": "2021-10-31T01:52:14.102200Z"
    }
   },
   "outputs": [],
   "source": [
    "company_sales_df.plot(kind='bar', stacked=True, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:32:21.917282Z",
     "start_time": "2021-10-31T05:32:21.688733Z"
    }
   },
   "outputs": [],
   "source": [
    "company_sales_df.plot(x = '_______', y = '________', \n",
    "                      kind = '________', \n",
    "                      color = 'dodgerblue',\n",
    "                      s = 250,\n",
    "                      figsize = (16,8), \n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Create a scatter plot using the DataFrame below. \n",
    "- Change the size of each dot to size 1000\n",
    "\n",
    "---\n",
    "Hint:\n",
    "- kind='scatter'\n",
    "- try the `s=` parameter: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T01:55:04.053261Z",
     "start_time": "2021-10-31T01:55:04.045759Z"
    }
   },
   "outputs": [],
   "source": [
    "sp_dict = {'x': [1, 2, 3, 4, 5], 'y': [2, 5, 3, 9, 12]}\n",
    "sp = pd.DataFrame(sp_dict)\n",
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T16:20:38.715845Z",
     "start_time": "2021-10-14T16:20:38.711902Z"
    }
   },
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"hist\"></a>\n",
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Single histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:36:15.281157Z",
     "start_time": "2021-10-31T05:36:15.278562Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate random numbers for lesson\n",
    "norm = np.random.standard_normal(5000)\n",
    "norm = pd.Series(norm)\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:36:16.577998Z",
     "start_time": "2021-10-31T05:36:16.314803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bins param adjusts the no. of bins\n",
    "norm.plot(kind='hist',figsize=(16,4), bins=50)  # try changing the bins number here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sns\"></a>\n",
    "## 2nd Package! - Seaborn\n",
    "- Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:38:48.818664Z",
     "start_time": "2021-10-31T05:38:48.816129Z"
    }
   },
   "outputs": [],
   "source": [
    "# import seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:38:52.019947Z",
     "start_time": "2021-10-31T05:38:52.010740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Refresh what's in our df\n",
    "company_sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"box\"></a>\n",
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T02:01:07.123061Z",
     "start_time": "2021-10-31T02:01:07.102396Z"
    }
   },
   "outputs": [],
   "source": [
    "# use the describe function to describe the dataframe\n",
    "company_sales_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T02:01:31.589556Z",
     "start_time": "2021-10-31T02:01:31.420595Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=company_sales_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap + Correlation\n",
    "- Add colors to numbers\n",
    "- Various colormaps suited for different purposes\n",
    "- For correlation, diverging colormaps should be used because numbers range from -1 to 1\n",
    "    - 0 having no color is best\n",
    "    - Further from 0 is darker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Variance: Statiscal Measurement of the SPREAD between numbers in the dataset:**    \n",
    "\n",
    "The higher the variance, the more spread out the data.\n",
    "\n",
    "$$s^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\bar x)^2}{\\large n-1}$$\n",
    "\n",
    "\n",
    "**Sample Standard Deviation: Square root of Sample Variance. Also a measurement of the SPREAD between numbers in the dataset**:  \n",
    "\n",
    "The higher the standard deviation, the more spread out the data.\n",
    "\n",
    "$$s = \\sqrt \\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\bar x)^2}{\\large n-1}$$\n",
    "\n",
    "\n",
    "**Covariance: Measurement of the extent to which two random variables are dependent on each other**:         \n",
    "\n",
    "The higher the covariance, the stronger the linear relationship. (This measurement is affected by the scale of your data)\n",
    "\n",
    "$$cov_{x,y}=\n",
    "\\frac{\\displaystyle\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y})}{\\large n-1}$$\n",
    "\n",
    "\n",
    "**Correlation: Also, a measure of how strongly two random variables are related**:  \n",
    "\n",
    "The higher the correlation, the stronger the linear relationship. (This measurement is **NOT** affected by the scale of your data). \n",
    "\n",
    "*This is preferred over covariance in most cases.*\n",
    "\n",
    "$$r_{x,y} = \\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\bar x)(y_i - \\bar y)}{\\sqrt{\\displaystyle\\sum_{i=1}^{n}(x_i - \\bar x)^2\\displaystyle\\sum_{i=1}^{n}(y_i - \\bar y)^2}}$$\n",
    "\n",
    "\n",
    "<img src=\"img/corr.png\" style=\"margin: 20px; height: 400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:50:43.944980Z",
     "start_time": "2021-10-31T05:50:43.936036Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation of each column and other columns\n",
    "correlation = company_sales_df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:51:30.533907Z",
     "start_time": "2021-10-31T05:51:30.313401Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(correlation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:52:32.727007Z",
     "start_time": "2021-10-31T05:52:32.709588Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"assets/penguins.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T05:57:50.473402Z",
     "start_time": "2021-10-31T05:57:46.471474Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pairplot\n",
    "sns.________(df, hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/data_cleaning.png\" style=\"margin: 20px; height: 400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has many functions to help process and manipulate data. Here are some that we can look at:\n",
    "- .dtypes\n",
    "- df.value_counts(), series.value_counts()\n",
    "- df.sort_values(by=?)\n",
    "- df.isnull()\n",
    "- df.duplicated()\n",
    "- df.drop_duplicates(subset=?)\n",
    "- df.apply()\n",
    "- df.map()\n",
    "- df.groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"stepsdc\"></a>\n",
    "### Common Steps in Cleaning Data:\n",
    "1. Handling Missing Data \n",
    "3. Encoding strings to numbers (because machine learning models deal with numbers only)\n",
    "4. Standardization\n",
    "5. Drop Outliers or duplicates (full/partial row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T06:15:44.604104Z",
     "start_time": "2021-10-31T06:15:44.601298Z"
    }
   },
   "outputs": [],
   "source": [
    "#import necessary libraries just in case you haven't import them\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"assets/insurance.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T02:39:40.054581Z",
     "start_time": "2021-10-31T02:39:40.002298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Look at samples, number of rows, columns and descriptive stats\n",
    "df.info() # observe Non-Null Count for missing values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and Sorting\n",
    "- Used to zoom in to particular parts of dataset\n",
    "- May not necessarily be throwing away rows, could be to create intermediate df to study a particular group of people\n",
    "- Statistics requires sampling the right subjects to form comparable groups when designing experiments\n",
    "- Machine learning requries filtering to remove outliers that harm model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise  \n",
    "With the df dataframe, do the following (the questions are independent of each other):   \n",
    "- Get users with age less than 20 and charges less than 2000, how many rows are there?\n",
    "- Filter dataframe to show old (above 60) and young (below 10)\n",
    "- Sort values according to age then gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clue 1: Still remember how to filter a dataframe?\n",
    "# sample_df['income'] > 10000\n",
    "# sample_df[ sample_df['income'] > 10000 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clue 2: After you have done the filter, you got to sort.\n",
    "# Check out pandas dataframe's function \"sort_values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code (create more cells if you need)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming, Removing Columns\n",
    "\n",
    "- remove spaces in column name (usually by replacing with underscore) to make dot_notation workable df.first_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T14:52:27.527629Z",
     "start_time": "2021-10-26T14:52:27.509590Z"
    }
   },
   "outputs": [],
   "source": [
    "mapping = {'charges':'costs'}\n",
    "\n",
    "df = df.______(columns = ______)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T02:48:04.721311Z",
     "start_time": "2021-10-31T02:48:04.703756Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping a column or a few columns\n",
    "df = df._____('region', _______)\n",
    "df\n",
    "# to drop a few columns, you need to give a list\n",
    "# df.drop(['age', 'sex'], axis=1)\n",
    "\n",
    "# axis = 1 refers to column. axis = 0 refers to row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicates \n",
    "- does it count both or only the extra copies? Multiple options at https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T06:29:07.711062Z",
     "start_time": "2021-10-31T06:29:07.679438Z"
    }
   },
   "outputs": [],
   "source": [
    "# gives a boolean index, you know how to use this already\n",
    "df.duplicated() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful trick: count number of duplicated items\n",
    "df.duplicated().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to really drop the duplicates\n",
    "df = df.___________() \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-place operations\n",
    "- `df.drop_duplicates(inplace=False)` by default\n",
    "- Many pandas operations have inplace parameter, using them is bad practice\n",
    "- Just assign back like `df = df.drop_duplicates()` for the change to take effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Functions in Pandas\n",
    "\n",
    "- **Objective:** get aggregate values of groups\n",
    "- Syntax is `df.groupby(col variable or string)` or `df.groupby(list_of_cols)` to create a groupby object\n",
    "- chain on an aggregation function, `df.groupby('smoker').mean()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping on 1 col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T02:53:59.067689Z",
     "start_time": "2021-10-31T02:53:59.056605Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped = df[['smoker', 'age', 'bmi']].______\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T15:07:01.296847Z",
     "start_time": "2021-10-26T15:07:01.281647Z"
    }
   },
   "outputs": [],
   "source": [
    "# if you just want the mean age\n",
    "grouped['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Group by `['sex', 'smoker']` with `.mean()` as aggregator to compute the average cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T15:22:58.707268Z",
     "start_time": "2021-10-26T15:22:58.703720Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "df[['smoker', 'sex', 'costs']].groupby([_________]).______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id =\"missing\"></a>\n",
    "### Handling Missing Data\n",
    "\n",
    "- There are several ways of handling missing data:\n",
    "    1. Drop   `df.drop()`  (remember to choose an axis)\n",
    "    2. Fill with `.fillna()`\n",
    "    3. Manipulate\n",
    "- We can check if our data by using a combination of ***isnull() or isna()*** function and ***sum()***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T06:54:49.161257Z",
     "start_time": "2021-10-31T06:54:49.132726Z"
    }
   },
   "outputs": [],
   "source": [
    "# no missing values, so everything is False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T06:54:51.487280Z",
     "start_time": "2021-10-31T06:54:51.480465Z"
    }
   },
   "outputs": [],
   "source": [
    "# Useful trick! Sum the columns to find number of missing values per col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are artificially making some values missing\n",
    "np.random.seed(0)\n",
    "df_null = df.mask(np.random.random(df.shape) < .1) # randomly masking 10% of values\n",
    "df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null.isnull().sum() # same trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Talking Point:\n",
    "**When do we decide to drop null values instead of filling it? What is the best way to fill missing values?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T03:25:59.760914Z",
     "start_time": "2021-10-31T03:25:59.754535Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the percentages of the null values per column\n",
    "num_of_row = df.shape[0]\n",
    "\n",
    "df_null.isnull().sum()/num_of_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before replacement\n",
    "df_null['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's populate the null values in age to be the median value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T07:00:42.248123Z",
     "start_time": "2021-10-31T07:00:42.237431Z"
    }
   },
   "outputs": [],
   "source": [
    "# always check to see that things are filled correctly\n",
    "df_null.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"func\"></a>\n",
    "### Using Functions\n",
    "\n",
    "- **Objective:** Populate and manipulate dataframe columns\n",
    "- map()\n",
    "- apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the values of the gender column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's try and map females to 0 and males to 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df.apply(func)  \n",
    "\n",
    "`.apply` allows you to apply a function each row or column  \n",
    "\n",
    "\n",
    "Here we have an example of a \"Standard Scaling\" function:\n",
    "\n",
    "$z = \\Large \\frac{x-\\bar x}{s}$\n",
    "\n",
    "- $\\bar x$ is the mean of the sample\n",
    "- $s$ is the standard deviation of the sample\n",
    "- This transformation will make z have mean of 0 and std of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T07:23:08.206515Z",
     "start_time": "2021-10-31T07:23:08.203610Z"
    }
   },
   "outputs": [],
   "source": [
    "# subtract every value by the mean of the column and divide by standard deviation\n",
    "# we have done the function for you\n",
    "def standard_scaling(column):\n",
    "    return (column - np.mean(column))/np.std(column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Let's break down the function that we just did:***\n",
    "\n",
    "1. Column is a 1D input to this function\n",
    "2. In each call of this function, a different column will be sent as input, and the standardized results will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T07:09:45.273781Z",
     "start_time": "2021-10-31T07:09:45.267452Z"
    }
   },
   "outputs": [],
   "source": [
    "# if you haven't load df\n",
    "# df = pd.read_csv(\"assets/insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T03:36:41.455152Z",
     "start_time": "2021-10-31T03:36:41.453177Z"
    }
   },
   "outputs": [],
   "source": [
    "# before\n",
    "df['bmi'].plot.hist()\n",
    "plt.title(f\"Before Standard Scaling - Mean: {df['bmi'].mean():.2f} Std: {df['bmi'].std():.2f}\",fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T07:10:11.990016Z",
     "start_time": "2021-10-31T07:10:11.798375Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's apply the function on each column!\n",
    "# default axis of apply is 0, each column gets sent as input \n",
    "# if axis=1 passed, each row gets sent as input (rarely do this)\n",
    "df[['costs','bmi']] = df[['costs','bmi']]._______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T07:14:35.808052Z",
     "start_time": "2021-10-31T07:14:35.619524Z"
    }
   },
   "outputs": [],
   "source": [
    "# after\n",
    "df['bmi'].plot.hist()\n",
    "plt.title(f\"After Standard Scaling - Mean: {df['bmi'].mean():.2f} Std: {df['bmi'].std():.2f}\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- Why does `df['charges'].apply(standard_scaling)` wrongly give all NaN (not a number)? (you have to `df[['charges']].apply(standard_scaling)`\n",
    "---\n",
    "- With `df['charges'].apply`, you are actually throwing away 1 dimension, `df[['charges']]` is a dataframe while `df['charges']` is a series doing series.apply(). \n",
    "- In series.apply, what gets sent the the applied function is each scalar number row by row instead of a whole column of 1d values\n",
    "- /np.std(column) inside `def standard_scaling` is divide by 0 since std of only 1 number is 0. \n",
    "- Numpy handles divide by 0 (infinity) as NaN\n",
    "\n",
    "---\n",
    "**Lesson**\n",
    "- Know types, dimensions, what type of object/shape is expected to be passed and what you are really passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "- Write an `average` function and use it in `df.apply(average)` to get average `age` and average `bmi` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T07:30:35.124471Z",
     "start_time": "2021-10-31T07:30:35.117662Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"assets/insurance.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "def average(__):\n",
    "    return _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes: Functions are objects that can be passed around\n",
    "- No need to `def average` at all, instead just `df.apply(np.mean)` , or more simply `df.mean()`\n",
    "    - This is unintuitive because you usually think np.mean() has to be used with () on some data\n",
    "    - `np.mean` is a function object, `np.mean()` is calling the function object, different things\n",
    "    - Passing `np.mean`to another function is delaying the call, to let another function do the calling (by applying `()` on the function object) for you\n",
    "- The data is automatically passed into the function for you by the pandas .apply framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T07:31:51.137217Z",
     "start_time": "2021-10-31T07:31:51.125044Z"
    }
   },
   "outputs": [],
   "source": [
    "df[['age','bmi']].apply(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Home Exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "1. Set the time as dataframe index\n",
    "2. Create 1 line plot for each stock on the same figure of reasonable size. How many datapoints are there? (Plot last 1000 points of every stock)\n",
    "3. When did each stock become first available? (first date of non-na value) `Hint: series.first_valid_index()`\n",
    "4. Plot only from 30 July 2021 to the last data point (See anything strange? Why do you think so?) `Hint: series.last_valid_index()`\n",
    "5. Plot from 20 July 2021 to the last data point (Can you explain the previous phenomena now?)\n",
    "6. BTC-USD looks like an outlier, plot all other stocks without that line (Use list comprehension or `stocks.columns.difference`)\n",
    "7. Select all data points from 2021 July (try using partial string indexing: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#partial-string-indexing) `Hint: need to convert default index to a DateTimeIndex using pd.to_datetime()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T14:35:51.454268Z",
     "start_time": "2021-10-09T14:35:51.438907Z"
    }
   },
   "outputs": [],
   "source": [
    "stocks = pd.read_csv('assets/stocks.csv')\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Create this output\n",
    "```\n",
    "sex     smoker\n",
    "female  no        0.514098\n",
    "        yes       0.419708\n",
    "male    no        0.485902\n",
    "        yes       0.580292\n",
    "dtype: float64\n",
    "```\n",
    "- The numbers represent the percentage of rows of no/yes in female, and percentage of rows of no/yes in male\n",
    "- Note how the inner level values (smoker) sum to 1 for each category on outer level (sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T15:53:20.004770Z",
     "start_time": "2021-10-26T15:53:19.985644Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"assets/insurance.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T16:00:43.787657Z",
     "start_time": "2021-10-26T16:00:43.766764Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to understand our data is to visualize it.\n",
    "What kind of graphs would you want to see to explore your data? \n",
    "\n",
    "1. Try to use what we've learned so far with data visualization and data cleaning\n",
    "2. What is the problem you are trying to solve with the Insurance dataset\n",
    "3. What are the questions you would ask to understand your data more?\n",
    "4. What kind of graphs would best represent the questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of all we learn't today to machine learning \n",
    "\n",
    "- Visualization\n",
    "    - Used to find outliers and missing values (can be outlier in 1d,2d,3d...)\n",
    "    - Outliers and missing values are removed/imputed based on how much is missing or how wrong is the value\n",
    "    - Histograms are used to check whether model fulfils modelling assumptions (eg. Linear regression in lesson 5 assume normally distributed residuals if the model is used for estimating coefficients instead of prediction) \n",
    "    - Type of data/goal of study influences type of pandas operation and type of plot\n",
    "        - Bar plot for Categorical data, to study prevalence (eg. count of red,blue,green)\n",
    "        - Histogram for Continuous data, to study distribution (eg. distribution of weights)\n",
    "        - Scatter plot for bi-variate data, to study relationships between 2 continuous (usually) columns\n",
    "        \n",
    "- Data Cleaning\n",
    "    - Deduplication for version control, dataframe may contain concatenated dataframes from different time periods, goal is to sort by time and always take most updated row for a particular set of column values. Naming csv files by time and adding it as a column before concatenating dfs together is common practice\n",
    "    - Filtering a subset of the population of rows to study a particular phenomena \n",
    "        - transactions occuring on weekend only\n",
    "        - website visits of people using android only\n",
    "        - people who have consistently been paying installments on time\n",
    "- Data transformation (eg. `df.map, df.apply, df.groupby(col).agg()`)\n",
    "    - Turn text into machine-interpretable numbers\n",
    "    - Encode a value to an abstract concept (`{\"terrible\":0,\"decent\":1,\"brilliant\":2}`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lesson Summary\n",
    "\n",
    "\n",
    "Let's review what we learned today. We:\n",
    "\n",
    "- performed data cleaning using python\n",
    "- drew relevant trends and insights from data analysis to support decisions\n",
    "- performed exploratory data analysis using python and pandas\n",
    "- communicated data driven insights using data visualization\n",
    "- handled missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Readings:\n",
    "- Visualization:\n",
    "    - Anatomy of a matplotlib figure: https://realpython.com/python-matplotlib-guide/\n",
    "    - Seaborn gallery: https://seaborn.pydata.org/examples/index.html\n",
    "\n",
    "- Pandas:\n",
    "    - Details on groupby analysis: https://pbpython.com/groupby-agg.html\n",
    "    - Pandas exercises https://github.com/guipsamora/pandas_exercises (same as lesson 3 link)\n",
    "    - Inplace or not: https://towardsdatascience.com/why-you-should-probably-never-use-pandas-inplace-true-9f9f211849e4\n",
    "\n",
    "- Statistics:\n",
    "    - What is covariance and correlation: https://gopalcdas.com/tag/sample-correlation-coefficient/\n",
    "    - Statquest: https://www.youtube.com/watch?v=SzZ6GpcfoQY&ab_channel=StatQuestwithJoshStarmer\n",
    "    \n",
    "- Types of data\n",
    "    - NOIR: https://builtin.com/data-science/data-types-statistics\n",
    "    - 3 Types of missingness: https://stefvanbuuren.name/fimd/sec-MCAR.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "479.427px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/vi_logo.png\" style=\"float: left; margin: 10px; height: 45px\">\n",
    "\n",
    "# Vertical Institute Data Science 101\n",
    "# Lesson 6: Classification Models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "#### Part 1: KNearest Neighbors\n",
    "**After this lesson, you will be able to:**\n",
    "- Define what classification models are\n",
    "- Understand KNN algorithm\n",
    "- Apply KNN to Iris dataset\n",
    "\n",
    "#### Part 2: Logistic Regression\n",
    "**After this lesson, you will be able to:**\n",
    "- Understand Logistic regression algorithm\n",
    "- Apply Logistic Regression to Wine dataset\n",
    "\n",
    "#### Part 3: Decision Trees and Random Forest Classification\n",
    "- Understand Decision Trees\n",
    "- Apply decision tree model to Loan Approval dataset\n",
    "- Understand Random Forest Classifier\n",
    "- Apply Random Forest Classifier to dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: KNearest Neighbors - First Model\n",
    "\n",
    "### What is Classification?\n",
    "- used to predict which class a data point is part of (discrete value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/scikit.png\" style=\"height: 600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"knn\"></a>\n",
    "### Introduction to KNN\n",
    "\n",
    "- *non-parametric, lazy learning algorithm* that predicts outcomes based on the similarity (nearness) of inputted features to the training set\n",
    "\n",
    "\n",
    "- __Non-parametric__: does not make assumptions about the underlying distribution of our data\n",
    "- __Lazy__: training phase is minimal - KNN uses all (or nearly all) of the training data\n",
    "- __Based on feature similarity__: how closely out-of-sample features resemble our training set determines how we classify a given data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/knn.png\" style=\"margin: 20px; height: 400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"adv\"></a>\n",
    "### Advantages and Drawbacks of KNN\n",
    "\n",
    "***Benefits***\n",
    "- Simple to understand and explain\n",
    "- Model training is fast\n",
    "- Can be used for classification and regression\n",
    "\n",
    "\n",
    "***Drawbacks***\n",
    "\n",
    "- Must store all of the training data\n",
    "- Prediction phase can be slow when n is large\n",
    "- Sensitive to irrelevant features\n",
    "- Sensitive to the scale of the data\n",
    "- Accuracy is (generally) not competitive with other supervised learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Bank customer churn dataset\n",
    "\n",
    "This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer. Let's explore it together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:15:26.839805Z",
     "start_time": "2021-11-07T05:15:26.834779Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import KNN\n",
    "from sklearn.______ import _______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:15:29.326853Z",
     "start_time": "2021-11-07T05:15:29.324242Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./assets/Churn_Modelling.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:15:29.678429Z",
     "start_time": "2021-11-07T05:15:29.675716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign your data and target\n",
    "X = data[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']]\n",
    "y = data['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:15:56.331985Z",
     "start_time": "2021-11-07T05:15:56.315753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same few steps as before!\n",
    "# 1. Initialize KNN\n",
    "model = _______________()\n",
    "\n",
    "# 2. fit data\n",
    "model.fit(_, _)\n",
    "\n",
    "# 3. predict the response values for the observations in X (\"test the model\")\n",
    "y_pred_class = model.predict(_)\n",
    "y_pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:17:32.330342Z",
     "start_time": "2021-11-07T05:17:32.327119Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute classification accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(__, ___________)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***What can we observe from the above accuracy? Is it considered as good or bad?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "To evaluate our model accurately, we always need to split our data into a **training set** and **testing set**.\n",
    "\n",
    "The training set is the data we use to fit our model, but our model should never see the data from the testing set at this stage.\n",
    "\n",
    "Only after the model is trained, we see how well the model predicts the target from the testing set."
   ]
  },
  {
   "attachments": {
    "Train-Test-Data-Split.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Train-Test-Data-Split.png](attachment:Train-Test-Data-Split.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:22:05.624522Z",
     "start_time": "2021-11-07T05:22:05.621128Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train, test, split\n",
    "from sklearn.model_selection import __________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:22:13.136507Z",
     "start_time": "2021-11-07T05:22:13.132426Z"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 1: split X and y into training and testing sets (using random_state for reproducibility)\n",
    "# Split X into X_train and X_test\n",
    "# Split y into y_train and y_test\n",
    "# All in one shot using one function!\n",
    "\n",
    "X_train, X_test, y_train, y_test = ___________(_, _, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:23:58.944387Z",
     "start_time": "2021-11-07T05:23:58.937033Z"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 2: train the model on the training set (using K=1)\n",
    "knn = ______________(n_neighbors = 1)\n",
    "knn.fit(______, ______)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:26:20.616865Z",
     "start_time": "2021-11-07T05:26:20.609924Z"
    }
   },
   "outputs": [],
   "source": [
    "# STEP 3: test the model on the testing set, and check the accuracy\n",
    "y_pred_class = ___.predict(______)\n",
    "\n",
    "# Checking out the accuracy metric for this model\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:26:26.589488Z",
     "start_time": "2021-11-07T05:26:26.578236Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's build a new model and see the performance!\n",
    "# KNN with 50 neighbors\n",
    "# Same few steps!\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=__) # fill in the argument\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = knn.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:26:32.115775Z",
     "start_time": "2021-11-07T05:26:32.106651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's build a new model and see the performance!\n",
    "# KNN with 64 neighbors\n",
    "# Same few steps!\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=__) # fill in the argument\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_class = knn.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In class Exercise 1:\n",
    "- Run the KNeighborsClassifer for a range of 2, 4, ... 20\n",
    "- Visualize n_neighbors on x-axis and test-set accuracy on y-axis\n",
    "- Use KNN on the loan-approval dataset (train_test_split and using numeric variables in X `df.select_dtypes('number')`\n",
    "- Target Column is `Loan_Status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and functions again just in case\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "loan = pd.read_csv('assets/loan-approval.csv')\n",
    "# Some preprocessing: mapping Y to 1, N to 0\n",
    "loan['Loan_Status'] = loan['Loan_Status'].map({'Y':1,\"N\":0}) \n",
    "\n",
    "loan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:46:22.066003Z",
     "start_time": "2021-11-07T05:46:22.058488Z"
    }
   },
   "outputs": [],
   "source": [
    "y = loan['_________']\n",
    "X = loan[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "       'Loan_Amount_Term', 'Credit_History']]\n",
    "\n",
    "X = X.fillna(X.mean()) # fill missing values with mean\n",
    "\n",
    "# Step 1: Train test split\n",
    "X_train, X_test, y_train, y_test = ___________(X, y, random_state = 42)\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Running a loop to change the K\n",
    "# In every iteration, we are building a new model with a different K and storing the results!\n",
    "for k in range(2,20+1,2):\n",
    "\n",
    "    knn = _____________(n_neighbors=k) # Step 2: Create the model object\n",
    "    \n",
    "    knn.fit(______, ______) # Step 3: Train the model\n",
    "    \n",
    "    y_pred_class = knn.predict(_____) # Step 4: Make prediction on test data\n",
    "    \n",
    "    scores.append(accuracy_score(y_test, _______)) # Step 5: Evaluate using accuracy\n",
    "    \n",
    "    \n",
    "plt.plot(scores)\n",
    "plt.xticks(ticks=range(10),labels=range(2,20+1,2))\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Test set Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model -  Logistic Regression\n",
    "- Arguably the most popular classification algorithm. Today we'll learn how it works and practice using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A (brief) review of regression models\n",
    "\n",
    "To understand how logistic regression works, we'll start with a refresher on standard regression. A regression with one predictor, **x1**, predicting **y** can be specified as:\n",
    "\n",
    "### $$E[y] = \\beta_0 + \\sum_{i}^N\\beta_ix_i$$\n",
    "\n",
    "Where:\n",
    "- **`E[y]`** is the expected value (mean) of y\n",
    "- **`i through N`** are the observations (rows) of the data\n",
    "- **`beta_0`** is the intercept\n",
    "- **`beta_i`** is the coefficient for the predictor **`x_i`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be using the same **Bank Customer Churn dataset** to learn about the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:48:22.881378Z",
     "start_time": "2021-11-07T05:48:22.864733Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# if you need to reload the data again\n",
    "data = pd.read_csv(\"./assets/Churn_Modelling.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:49:04.495153Z",
     "start_time": "2021-11-07T05:49:04.490475Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Normalize\" the non-target columns\n",
    "\n",
    "**Normalization** in this case means subtracting the column means and dividing by the column standard deviations.\n",
    "\n",
    "- The **`.mean()`** DataFrame function can calculate the column means\n",
    "- The **`.std()`** DataFrame function can calculate the column standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "\n",
    "X = data[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']]\n",
    "y = data['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE Normalization\n",
    "print(X.mean()) # Different mean\n",
    "print(X.std()) # Wildly different standard deviations\n",
    "\n",
    "# Some models like logistics regression don't like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T05:51:20.265238Z",
     "start_time": "2021-11-07T05:51:20.248103Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# AFTER Normalization\n",
    "X_standardized = (X - X.mean()) / X.std()\n",
    "\n",
    "print(X_standardized.mean()) # The column mean are all 0 (very close to zero) now!\n",
    "print(X_standardized.std()) # The standard deviation are all 1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is logistic regression?\n",
    "\n",
    "As the name implies, logistic regression is also a regression. There is still an intercept and coefficients multiplied by each predictor. \n",
    "\n",
    "In the case of logistic regression, however, the target variable is **categorical** as is the case in all classification problems, and therefore the regression is solving for the **probability of classes in the target variable** rather than the mean value of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"th1\"></a>\n",
    "###  In class Exercise 2: Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the wine dataset, finish the code below and train a model to determine if the wine is red or white. Use the comments to guide you through the steps of creating a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T10:18:54.341492Z",
     "start_time": "2021-10-10T10:18:54.337551Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.________ import ______________\n",
    "\n",
    "# initialize Xs and y\n",
    "X = data[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']]\n",
    "y = data['Exited']\n",
    "\n",
    "# initialize logistic regression model\n",
    "logreg = _______________()\n",
    "\n",
    "# train test split\n",
    "______, X_test, _____, y_test = _________(X, y, random_state=0)\n",
    "\n",
    "# fit X_train and y_train\n",
    "logreg.fit(_______, _______)\n",
    "\n",
    "# use model to predict X_test\n",
    "y_pred = logreg.predict(______)\n",
    "\n",
    "# compare predictions to y_test\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we used the standardised X instead? Is the accuracy better? YES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# train test split\n",
    "# Use X_standardized instead of X\n",
    "X_train, X_test, y_train, y_test = train_test_split(_________, y, random_state=0)  \n",
    "\n",
    "# fit X_train and y_train\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# use model to predict X_test\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# compare predictions to y_test\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Decision Trees\n",
    "\n",
    "- Visual Introduction: http://www.r2d3.us/visual-intro-to-machine-learning-part-1/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "- machine learning model that develops a series of yes or no rules to explain the differences present in the outcome variable\n",
    "- non-parametric, hierarchical classification and regression technique\n",
    "\n",
    "    1. Root - starting point of the decision tree\n",
    "    2. Nodes - subsequent branching points\n",
    "    3. Leaves - nodes that do not split any further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/dt.jpg\" style=\"margin: 20px; height: 350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elements of Decision Trees\n",
    "1. __Greedy__ - algorithm makes locally optimal decision at each step\n",
    "2. __Recursive__ - splits tasks into subtasks, solves each in the same way\n",
    "3. __Local optimum__ - solution for a given neighborhood of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types of Splits:\n",
    "\n",
    "1. Entropy \n",
    "2. Gini Index\n",
    "\n",
    "___\n",
    "- Both are ways to calculate information gain\n",
    "- Since the entropy/gini before splitting is the same for any split, it can be left out during information gain calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the same Churn_Modelling.csv dataset\n",
    "\n",
    "- We are going to test the new model to see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T02:55:13.454315Z",
     "start_time": "2021-11-07T02:55:13.451771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the model \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Just in case you haven't load the data\n",
    "data = pd.read_csv(\"./assets/Churn_Modelling.csv\")\n",
    "X = data[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']]\n",
    "y = data['Exited']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T02:55:14.392962Z",
     "start_time": "2021-11-07T02:55:14.390893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize decision tree model\n",
    "tree = ______________(max_depth = 2)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit X_train and y_train\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# use model to predict X_test\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# compare predictions to y_test\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We normally tune the `max_depth` hyper-parameter in a decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary to hold the results\n",
    "scores = {}\n",
    "\n",
    "# looping through 2 to 18\n",
    "# we are building an entirely new model in each iteration\n",
    "for depth in range(2, 18+1, 4):\n",
    "    \n",
    "    tree = DecisionTreeClassifier(max_depth = _____) # we are using depth which changes every iteration\n",
    "    \n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    y_preds = tree.predict(X_test)\n",
    "    \n",
    "    # store the accuracy in the dictionary\n",
    "    scores[depth] = accuracy_score(y_test,y_preds) \n",
    "\n",
    "score_table = pd.Series(data=scores)\n",
    "score_table\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"advdt\"></a>\n",
    "### Advantages and Disadvantages of Decision Trees\n",
    "\n",
    "***Advantages***\n",
    "- Decisions are easy to understand and interpret\n",
    "- Weight and importance of each feature becomes clear\n",
    "- Numerical and categorical features can be used naturally\n",
    "- Trees are a natural multi-class classifier\n",
    "\n",
    "***Disadvantages***\n",
    "- Overfit to training data with complex trees\n",
    "- Small changes in input data can result in totally different trees\n",
    "- Can make mistakes with unbalanced classes\n",
    "- Requires large datasets to build robust rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics for Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T13:47:21.211842Z",
     "start_time": "2021-10-10T13:47:21.206313Z"
    }
   },
   "source": [
    "<img src=\"img/confusion.jpeg\" style=\"height: 600px\">\n",
    "<img src=\"img/confusion.png\" style=\"height: 550px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Recall** (Sensitivity)\n",
    "- **Precision**\n",
    "- **F1** (Harmonic mean of Precision and Recall)\n",
    "\n",
    "$$precision=\\frac{TP}{TP+FP};$$\n",
    "\n",
    "$$recall=\\frac{TP}{TP+FN};$$\n",
    "\n",
    "$$F_1=2.\\: \\frac{precision\\: .\\: recall}{precision+recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which metric do you care about?\n",
    "- **Precision** if cost of False Positives are high\n",
    "- **Recall** if cost of False Negatives are high "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T07:17:50.005687Z",
     "start_time": "2021-11-07T07:17:49.822956Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ___________\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = ___________(y_test, y_preds) # calculate\n",
    "\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot() # visualize in a nicer format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Recall formula, what is the value of recall in this example?  \n",
    "#### Using the Precision formula, what is the value of precision in this example?  \n",
    "#### Using the F1 formula, what is the value of F1 in this example?     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver operating characteristic curve (ROC) (Bonus!)\n",
    "- A plot of false positive rate on x against true positive rate on y\n",
    "- Area under curve goes from 0.5 (random model) to 1 (ideal), although a worst than random model (<0.5) is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T04:45:22.771071Z",
     "start_time": "2021-11-07T04:45:22.629451Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ________, ________\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Compute the predictions. Getting the probability of True class\n",
    "y_score = tree.predict_proba(X_test)[:,1]\n",
    "print(y_score) \n",
    "\n",
    "# the roc_curve function can give you the false positive rate and true positive rate\n",
    "fpr, tpr, _ = ______(y_test, y_score, pos_label = tree.classes_[1])\n",
    "\n",
    "# with the FPR and TPR, we can plot the ROC curve\n",
    "roc_display = _____________(fpr = fpr, tpr = tpr).plot()\n",
    "\n",
    "# note roc uses .predict_proba(), the unthresholded probabilities. \n",
    "# Code won't error with .predict() (less granular values default threholded at 0.5) but is theoretically wrong\n",
    "\n",
    "# Computing the AUC score\n",
    "print('AUC score: ', ___________(y_test, y_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"conclusion\"></a>\n",
    "## Lesson Summary\n",
    "\n",
    "\n",
    "Let's review what we learned today. We:\n",
    "\n",
    "- Conducted statistical modelling of different datasets to derive solutions\n",
    "- Walk-through of several classification models: KNN, Logistic Regression, Decision Trees and Random Forest Classifier\n",
    "- Identify which models would churn good results based on the characteristics and process of the algorithms\n",
    "- Used scikit learn package to perform advanced computational methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readings\n",
    "- Visual Intro to Decision Trees: http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n",
    "- https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "- Playground to learn models: https://ml-playground.com\n",
    "- Data Leakage: https://www.kaggle.com/alexisbcook/data-leakage\n",
    "- ROC/Precision-Recall details\n",
    "    - https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html\n",
    "    - https://www.kaggle.com/lct14558/imbalanced-data-why-you-should-not-use-roc-curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "426.198px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
